# Emotion-Detection-based-on-Facial-Expression

This project focuses on building an emotion recognition system using Vision Transformers (ViT), a pre-trained model designed for image classification. Implemented in Python, it leverages libraries such as OpenCV, Hugging Face, Pandas, and PyTorch to achieve robust performance.

The model is trained on the AffectNet dataset, capable of identifying eight primary emotions under challenging conditions, including occlusion, varied lighting, and diverse facial poses. The system was evaluated on unseen data, achieving an accuracy of 72%, which is a significant improvement over existing benchmarks.
